<?xml version='1.0' encoding='utf-8' ?>
<!DOCTYPE article [
<!ENTITY % BOOK_ENTITIES SYSTEM "Release_Notes.ent">
%BOOK_ENTITIES;
<!ENTITY % sgml.features "IGNORE">
<!ENTITY % xml.features "INCLUDE">
<!ENTITY % DOCBOOK_ENTS PUBLIC "-//OASIS//ENTITIES DocBook Character Entities V4.5//EN" "/usr/share/xml/docbook/schema/dtd/4.5/dbcentx.mod">
%DOCBOOK_ENTS;
]>
<article version="5.0" xmlns="http://docbook.org/ns/docbook"
	 xmlns:xlink="http://www.w3.org/1999/xlink"
	 xmlns:xi="http://www.w3.org/2001/XInclude">
  <info xml:id="info-Qlustar_Cluster_OS-Release_Notes-Release_Notes">
    <title>Release Notes</title>
    <subtitle></subtitle>
    <productname>Qlustar Cluster OS</productname>
    <productnumber>10.0</productnumber>
    <edition>1</edition>
    <abstract>
      <para>
	Qlustar 9.2 is a major feature release of the 9.x series. It ships QluMan 3.0 that
	introduces a powerful new management and operating interface for Slurm. Under the hood,
	a completely new messaging architecture <classname>QluNet</classname> has been
	implemented. It serves as the communication backbone for all QluMan components.
      </para>
      <para>
	We also introduced the <classname>Qlustar BioStack</classname> delivering a huge
	selection of easily deployable and cluster-optimized Bioinformatics software packages
	based on <link xlink:href="https://www.debian.org/devel/debian-med/___blank___">the
	DebianMed project</link>. These packages are grouped in tasks and can conveniently be
	selected when setting up a chroot for the cluster nodes.
      </para>
      <para>
	The highlights among the numerous component updates and bug fixes are: Slurm 16.5.8,
	OpenMPI 2.0.2, CUDA 8.0 and BeeGFS 6. New in this release is support for Singularity
	containers.
      </para>
    </abstract>
    <author><orgname><inlinemediaobject><imageobject>
	<imagedata fileref="Common_Content/images/qlustar-logo.png" format="PNG" />
      </imageobject></inlinemediaobject></orgname></author>
  </info>
  <section>
    <title>Basic Info</title>
      <para>
	The Qlustar 9.2 <classname>core platform</classname> is based on Ubuntu 14.04.5 and the
	additional Debian <classname>edge platform</classname> on Debian 7.9. Both include all
	security fixes and other package updates published before April 19th 2017. Available
	security updates relevant to Qlustar 9.2, that have appeared after this date, will be
	announced on the Qlustar website and in the Qlustar security news-letter.
      </para>
  </section>
  <section>
    <title>New features</title>
    <section>
      <title>QluMan 3.0</title>
	<variablelist>
	  <varlistentry>
	    <term>Slurm management interface</term>
	    <listitem>
	      <para>
		The all new management interface for Slurm provides a nice overview of cluster
		and job usage, a fancy job management interface that includes customizable job
		filters, a node state management tool to display and manipulate the Slurm state
		of compute nodes, a powerful dialog to view, create and modify reservations, as
		well as sub-windows that present cluster usage, fairshare and job priority
		data.
	      </para>
	      <para>
		Additionally, it includes an interface to Slurm accounting that allows to view,
		create and modify Slurm accounts and Slurm users. Configured QOS are also
		viewable in a separate dialog. See <link
		xlink:href="../QluMan_Guide/index.html#sec-Slurm-Manage___blank___"> the
		corresponding section</link> in the QluMan guide to read about all the
		capabilities of the new Slurm component.
	      </para>
	      <para>
		All frequently changing Slurm state data like job/node information, cluster
		usage etc. is automatically updated in real-time in the corresponding GUI
		clients. Update intervals can be individually customized for different data
		types to allow for an optimal cluster-specific compromise between generated
		network traffic/server load and desired (high) update frequency.
	      </para>
	    </listitem>
	  </varlistentry>
	  <varlistentry>
	    <term>QluNet Messaging Architecture</term>
	    <listitem>
	      <para>
		QluMan's messaging architecture has been completely redesigned and extended to
		allow for flexible additions of future QluMan server components and is now
		available as a separately packaged component called
		<classname>QluNet</classname>.
	      </para>
	      <para>
		A new router daemon (<firstterm>qluman-router</firstterm>) has become the
		central hub for all messages exchanged between QluMan components. Among other
		tasks, it is responsible for managing the registration of new QluMan network
		nodes (like the qlumand, GUI client, etc.) and monitoring the availability of
		existing ones besides its main task of routing messages from a sending QluMan
		component to the correct destination.
	      </para>
	      <para>
		The new Slurm component e.g. includes a separate daemon
		(<firstterm>qluman-slurmd</firstterm>) which GUI clients can now talk to
		directly via the router without qlumand being involved. Subscription channels
		provide real-time updates of necessary information from the server components
		to the connected GUI clients.
	      </para>
	    </listitem>
	  </varlistentry>
	  <varlistentry>
	    <term> Miscellaneous</term>
	    <listitem>
	      <para>
		<itemizedlist>
		  <listitem>
		    <para>
		      The RXEngine dialog has a new <link
		      xlink:href="../QluMan_Guide/index.html#sec-RXE-Edit-Custom___blank___">
		      editor for the history of custom commands</link>. This allows convenient
		      book-keeping and rearrangement of recently executed command lines.
		    </para>
		  </listitem>
		  <listitem>
		    <para>
		      New LEDs at the bottom of the main QluMan window indicate the <link
		      xlink:href="../QluMan_Guide/index.html#sec-connection-status___blank___">
		      connection status</link> of a GUI session to the QluMan server
		      components.
		    </para>
		  </listitem>
		  <listitem>
		    <para>
		      It is now possible to control (enable/disable)
		      <firstterm>hyper-threading</firstterm> of compute nodes CPUs from within
		      QluMan by setting the corresponding generic property.
		    </para>
		  </listitem>
		  <listitem>
		    <para>
		      QluMan's server components provide better control of logging levels in
		      their configuration files. Each component now has its own config file.
		    </para>
		  </listitem>
		  <listitem>
		    <para>
		      The QluMan GUI qluman-qt is no longer installed on the cluster head-node
		      or a chroot during installation. If you really want to run it as a remote
		      application from the cluster, you'll have to install it manually
		      (<code>apt-get install qluman-qt</code>). However, it is recommended to
		      run it locally from your Linux workstation either by installing the
		      package directly (if on Debian/Ubuntu) or via the provided <link
		      xlink:href="../First_Steps_Guide/index.html#sec-QluMan-Workstation-container___blank___">container-based
		      packages</link> (Singularity or Docker).
		    </para>
		  </listitem>
		</itemizedlist>
	      </para>
	    </listitem>
	  </varlistentry>
	</variablelist>
    </section>
    <section>
      <title>Container Support</title>
      <para>
	Qlustar now fully supports the two container technologies <link
	xlink:href="https://docs.docker.com___blank___">Docker</link> and
	<link xlink:href="http://singularity.lbl.gov/___blank___">Singularity</link>.
      </para>
    </section>
  </section>
  <section>
    <title>Major component updates</title>
      <para>
	<variablelist>
	  <varlistentry>
	    <term>Slurm</term>
	    <listitem>
	      <para>
		Qlustar 9.2 introduces the Slurm 16.5 series with the current version being
		16.5.8.
	      </para>
	    </listitem>
	  </varlistentry>
	  <varlistentry>
	    <term>OFED Infiniband stack</term>
	    <listitem>
	      <para>
		Qlustar 9.2 ships the recently released OFED 3.18-2 Infiniband stack including
		all necessary components.
	      </para>
	    </listitem>
	  </varlistentry>
	  <varlistentry>
	    <term>OpenMPI</term>
	    <listitem>
	      <para>
		Qlustar 9.2 introduces the new OpenMPI 2.0 series with the most recent version
		2.0.2.
	      </para>
	    </listitem>
	  </varlistentry>
	  <varlistentry>
	    <term>Nvidia CUDA</term>
	    <listitem>
	      <para>
		Qlustar 9.2 provides optimal support for Nvidia GPU hardware by supplying
		pre-compiled and up-to-date kernel drivers as well as CUDA 8.0.
	      </para>
	    </listitem>
	  </varlistentry>
	  <varlistentry>
	    <term>BeeGFS</term>
	    <listitem>
	      <para>
		Qlustar 9.2 ships the latest BeeGFS version 6.7 and provides ready-to-use image
		modules based on it for real easy deployment of this ultra-fast parallel
		filesystem backed by ZFS on your storage cluster.
	      </para>
	    </listitem>
	  </varlistentry>
	  <varlistentry>
	    <term>ZFS Filesystem</term>
	    <listitem>
	      <para>
		Qlustar 9.2 updates ZFS to version 0.6.5.8 including a number of bug-fixes.
	      </para>
	    </listitem>
	  </varlistentry>
	</variablelist>
      </para>
  </section>
  <section>
    <title>Other package version updates</title>
    <para>
      <itemizedlist>
	<listitem>
	  <para>
	    <classname>Intel/PGI Compiler support</classname>: The Qlustar wrapper packages
	    have been updated to support the new versions Intel Parallel Studio 2017 and PGI
	    2016. Corresponding OpenMPI package variants for these compilers are also provided.
	  </para>
	</listitem>
	<listitem>
	  <para>
	    <classname>openblas</classname>: 0.2.19
	  </para>
	</listitem>
	<listitem>
	  <para>
	    <classname>lapack</classname>: 3.7.0
	  </para>
	</listitem>
	<listitem>
	  <para>
	    <classname>HPL Linpack</classname>: 2.2
	  </para>
	</listitem>
	<listitem>
	  <para>
	    <classname>freeipmi</classname>: 1.5.5
	  </para>
	</listitem>
      </itemizedlist>
    </para>
  </section>
  <section>
    <title>General changes/improvements</title>
      <para>
	<itemizedlist>
	  <listitem>
	    <para>
	      <classname>Slurm</classname>
	    </para>
	    <itemizedlist>
	      <listitem>
		<para>
		  Changes in the Qlustar Slurm default config (shown below as a diff)
		</para>
		<screen>
-TaskPlugin=task/cgroup
-TaskPluginParam=Cpusets,Verbose
+TaskPlugin=task/affinity,task/cgroup
+TaskPluginParam=Sched

-#DefMemPerCPU=0
+DefMemPerCPU=1024
-SelectTypeParameters=CR_CPU
+SelectTypeParameters=CR_CPU_Memory

+# Preemption
+PreemptType=preempt/qos
+PreemptMode=requeue

+PriorityFlags=FAIR_TREE
+FairShareDampeningFactor=5
-PriorityWeightFairshare=1000
+PriorityWeightFairshare=5000

-AccountingStorageEnforce=0
+AccountingStorageEnforce=limits,qos,nosteps
		</screen>
	      </listitem>
	      <listitem>
		<para>
		  New job submit parameter <literal>--gres-flags=enforce-binding</literal> that
		  allows e.g. to bind Slurm tasks of a submitted job to the correct CPU as
		  configured in a GRES definition.
		</para>
	      </listitem>
	      <listitem>
		<para>
		  A base setup for Slurm accounting is now automatically initialized provided
		  that Slurm was chosen as an option during installation. Furthermore, new
		  cluster users are automatically added to the default Slurm account
		  <emphasis>users</emphasis>. This is defined in the so-called add-user-hook
		  <filename>/etc/qlustar/common/add-user-hook</filename> of the <link
		  xlink:href="../Administration_Manual/index.html#admin-man-sect-user-manage___blank___">adduser.sh
		  script</link>
		</para>
	      </listitem>
	    </itemizedlist>
	  </listitem>
	  <listitem>
	    <para>
	      <classname>Parallelized Online Update</classname>: The <link
	      xlink:href="../Administration_Manual/index.html#updating-nodes___blank___">Qlustar
	      online update mechanism</link> for net-booted cluster nodes has added parallelism
	      as well as auto-detection of the image type needed for the update of their node
	      OS leading to maximum simplicity. Processing speed has improved dramatically to
	      allow updating of up to a thousand nodes in less than five minutes.
	    </para>
	  </listitem>
	  <listitem>
	    <para>
	      <classname>NFS path for applications</classname>: The default NFS path to be used
	      by an admin for custom applications installed outside of the packaging system has
	      changed to <filename>/apps/local</filename>. This affects only new installations.
	    </para>
	  </listitem>
	  <listitem>
	    <para>
	      <classname>Infiniband</classname>: A new kernel parameter
	      <literal>tune_ib_qib</literal> was added to activate auto-tuning of Intel
	      Truescale adapters.
	    </para>
	  </listitem>
	  <listitem>
	    <para>
	      <classname>Disk auto-setup</classname>: Make use of ZFS volumes for swap safe.
	    </para>
	  </listitem>
	  <listitem>
	    <para>
	      <classname>Lustre</classname>: Added additional config option
	      <literal>ko2iblnd_conf</literal> to allow for inhomogeneous IB clusters with a
	      mix of IB cards.
	    </para>
	  </listitem>
	  <listitem>
	    <para>
	      <classname>Ssh known_hosts file</classname>: On the head-nodes, this is now a
	      real file instead of a link which simplifies handling of HA head-nodes.
	    </para>
	  </listitem>
	  <listitem>
	    <para>
	      <classname>Bash completion for users</classname>: The Bash setup for users now
	      activates full support for program dependent completion provided by many Debian
	      software packages.
	    </para>
	  </listitem>
	  <listitem>
	    <para>
	      <classname>Installer</classname>: Supports NVME boot disks.
	    </para>
	  </listitem>
	  <listitem>
	    <para>
	      <classname>Netboot nodes</classname>: Set timezone from head-node's config.
	    </para>
	  </listitem>
	</itemizedlist>
      </para>
  </section>
  <section>
    <title>Update instructions</title>
    <task>
      <title></title>
      <procedure>
	<step>
	  <title>Preparations</title>
	  <para>
	    Upgrading to Qlustar 9.2 is only supported from a 9.1.x release.
	  </para>
	  <note><para>
	    Make sure that you have no unwritten changes in the QluMan database. If you do,
	    write them to disk as described in the <link
	    xlink:href="../QluMan_Guide/index.html#sec-Writing-Config-Files___blank___">
	    QluMan Guide</link> before proceeding with the update.
	  </para></note>
	</step>
	<step>
	  <title>Update to 9.2 package sources list</title>
	  <para>
	    The Qlustar apt sources list needs to be changed as follows both on the
	    head-node(s) and in all chroot(s) that should be updated.
	    <screen>
<prompt>0 root@cl-head ~ #</prompt>
<command>apt-get update</command>
<prompt>0 root@cl-head ~ #</prompt>
<command>apt-get install qlustar-sources-list-9.2</command>
	    </screen>
	  </para>
	</step>
	<step>
	  <title>Update packages</title>
	  <para>
	    Now proceed as explained in the <link
	    xlink:href="../Administration_Manual/index.html#chap-Updating-Qlustar___blank___">
	    Qlustar Administration Manual</link>.
	  </para>
	</step>
	<step>
	  <title>Install new QluMan packages</title>
	  <para>
	    QluMan 3.0 has two new server components and corresponding packages that need to be
	    installed and activated. To do so, execute the following on the head-node:
	    <screen>
<prompt>0 root@cl-head ~ #</prompt>
<command>apt-get install qluman-router qluman-slurmd</command>
	    </screen>
	    If your cluster doesn't have slurm installed, you can skip
	    <emphasis>qluman-slurmd</emphasis>. Once installed, activate the daemons for
	    automatic startup at boot time by setting <literal>RUN=yes</literal> in the
	    packages default files <filename>/etc/default/qluman-router</filename> and
	    <filename>/etc/default/qluman-slurmd</filename>.
	  </para>
	</step>
	<step>
	  <title>Reboot head-node(s)</title>
	  <para>
	    Initially only reboot the head-node(s).
	  </para>
	</step>
	<step>
	  <title>Regenerating Qlustar images</title>
	  <para>
	    Most likely you will also have to regenerate your Qlustar images with the 9.2 image
	    modules. To accomplish this, you'll have to select <emphasis>Version 9.2</emphasis>
	    in the QluMan <link
	    xlink:href="../QluMan_Guide/index.html#sec-Qlustar-OS-Images___blank___">
	    Qlustar Images dialog</link>.
	  </para>
	</step>
	<step>
	  <title>Write config file changes</title>
	  <para>
	    To activate all changes in the QluMan database that were introduced by the update,
	    they need to be written to disk now. Check the QluMan Guide about <link
	    xlink:href="../QluMan_Guide/index.html#sec-Writing-Config-Files___blank___"> how to
	    write such changes</link>.
	  </para>
	</step>
	<step>
	  <title>Reboot all netboot nodes</title>
	  <para>
	    After the regeneration of the images is complete, you can reboot all other nodes in
	    the cluster, including virtual FE nodes. This completes the update procedure.
	  </para>
	</step>
      </procedure>
    </task>
  </section>
  <section>
    <title>Changelogs</title>
    <para>
      A detailed log of changes in the image modules can be found in the directories
      <filename>/usr/share/doc/qlustar-module-&#60;module-name&#62;-*-amd64-9.2.0</filename>.
      As an example, in the directory
      <filename>/usr/share/doc/qlustar-module-core-precise-amd64-9.2.0</filename> you will find
      a summary changelog in <filename>core.changelog</filename>, a complete list of packages
      with version numbers entering the current core module in
      <filename>core.packages.version.gz</filename>, a complete changelog of the core modules
      package versions in <filename>core.packages.version.gz</filename> and finally a complete
      log of changed files in <filename>core.contents.changelog.gz</filename>.
      </para>
      </section>
</article>

