<?xml version='1.0' encoding='utf-8' ?>
<!DOCTYPE section [
<!ENTITY % BOOK_ENTITIES SYSTEM "administration-manual.ent">
%BOOK_ENTITIES;
<!ENTITY % sgml.features "IGNORE">
<!ENTITY % xml.features "INCLUDE">
<!ENTITY % DOCBOOK_ENTS PUBLIC "-//OASIS//ENTITIES DocBook Character Entities V4.5//EN" "/usr/share/xml/docbook/schema/dtd/4.5/dbcentx.mod">
%DOCBOOK_ENTS;
]>
<section xmlns="http://docbook.org/ns/docbook"
 xmlns:xlink="http://www.w3.org/1999/xlink"
 xmlns:xi="http://www.w3.org/2001/XInclude"
 xml:id="admin-man-sect-boot-process">
  <title>Boot Process</title>
  <indexterm><primary>Boot Process</primary></indexterm>
  <para>
    This section describes the boot process of Qlustar cluster-nodes.
  </para>
  <section xml:id="admin-man-sect-comp-node-boot">
    <title>Compute-node booting</title>
    <indexterm><primary>Boot Process</primary>
    <secondary>Compute-node booting</secondary></indexterm>
    <para> 
      The boot process of the compute-nodes follows precise rules. It takes place in six
      steps:
    </para>
    <orderedlist>
      <listitem>
	<para>
	  The PXE boot ROM of the network card sends a DHCP request. If the node is already
	  registered in QluMan, the request is answered by the DHCP server running on the
	  head-node(s), allowing the adapter to configure its basic IP settings.
	</para>
      </listitem>
      <listitem>
	<para>
	  The boot ROM requests a PXE loader program from the TFTP server on the head-node (the
	  TFTP server specified by DHCP could also be on another node, but this is not the
	  default). The PXE loader is then sent to the compute-node via TFTP.
	</para>
      </listitem>
      <listitem>
	<para>
	  PXELinux downloads the Qlustar Linux kernel and the assigned initial RAM-disk image
	  and boots the kernel. This image doesn't hold the final OS, it has just enough
	  functionality to download the real OS image in the next step.
	</para>
      </listitem>
      <listitem>
	<para>
	  A Qlustar specific script <filename>/init</filename> is executed as the initial init
	  process. This script sets up the unionfs filesystem structure as well as basic
	  networking functionality and finally starts the Qlustar multicast client to download
	  the real OS image assigned to the node and delivered by the Qlustar multicast image
	  server <classname>ql-mcastd</classname>. This image is unpacked into the path
	  <filename>/union/image</filename>.
	</para>
	<para>
	  The system then moves to the next boot stage by changing the root filesystem to the
	  new unpacked OS image. Control is now passed to the 2nd Qlustar init script
	  <filename>/sbin/init.qlustar</filename>.
	</para>
      </listitem>
      <listitem>
	<para>
	  <filename>/sbin/init.qlustar</filename> first executes
	  <application>systemd-udevd</application> to trigger the auto-loading of kernel
	  drivers and then starts <classname>QluMan execd</classname> in a one-shot
	  configure-mode. Hereby <classname>QluMan execd</classname> a) receives all the
	  node-specific options from <classname>qlumand</classname> running on the head-node
	  and b) executes corresponding scripts to process the options received.
	</para>
	<para>
	  This dynamic customization/configuration of the node must be done before systemd
	  starts. Among others, the following tasks are performed at this stage: Initialization
	  of local disks, setup of systemd units for QluMan defined <classname>Network FS
	  mounts</classname>, <classname>pam</classname> customization,
	  <classname>sssd</classname> customization, <classname>OpenSM</classname>
	  configuration (if desired) and a check whether <classname>NTP</classname> can
	  synchronize the time from the head-node(s).
	</para>
	<para>
	  Log files concerning this boot phase are located under
	  <filename>/var/log/qlustar</filename>. Adding the parameter
	  <emphasis>early-shell</emphasis> to the kernel cmdline, will interrupt the boot
	  process when entering <filename>/sbin/init.qlustar</filename> and give the
	  opportunity to debug in case of possible problems. The kernel parameter
	  <emphasis>debug</emphasis> will produce lots of debug messages during this phase.
	</para>
      </listitem>
      <listitem>
	<para>
	  When all the above is finished, control is finally passed to
	  <classname>systemd</classname> as the final init process. From here on, the boot
	  procedure proceeds in the standard Linux fashion.
	</para>
      </listitem>
    </orderedlist>
    <note>
      <para>
	The details of the node boot process have changed substantially while going from
	Qlustar 9.2 to 10.0, then 10.1 and finally 11.0. So make sure you check the
	documentation of the release you're running to obtain correct information.
      </para>
    </note>
  </section>
  <section xml:id="admin-man-sect-tftp-boot-serv">
    <title>TFTP Boot Server</title>
    <indexterm><primary>Boot Process</primary>
    <secondary>TFTP Boot Server</secondary></indexterm>
    <para>
      The <classname>TFTP</classname> server component of <classname>dnsmasq</classname>
      transfers the boot image to the compute-nodes. All files that should be served by tftp
      must reside in the directory <filename>/var/lib/tftpboot</filename>. On a Qlustar
      installation, it contains three symbolic links:
    </para>
<screen>
pxelinux.0 -> <filename>/usr/lib/syslinux/pxelinux.0</filename>
pxelinux.cfg -> <filename>/etc/qlustar/pxelinux.cfg</filename>
qlustar -> <filename>/var/lib/qlustar</filename>
</screen>
    <para>
      The directory <filename>/etc/qlustar/pxelinux.cfg</filename> contains the PXE boot
      configuration files for the compute-nodes. There is a default configuration that applies
      to any node without an assigned custom boot configuration in QluMan. For every host with
      a custom boot configuration, QluMan adds a symbolic link pointing to the actual
      configuration file. The links are named after the node's <parameter>Hostid</parameter>,
      which you can find out with the <command>gethostip</command> command. For more details
      about how to define boot configurations see the corresponding section of the <link
      xlink:href="../QluMan_Guide/index.html#sec-Boot-Configs___blank___">QluMan Guide</link>.
    </para>
  </section>
  <section xml:id="admin-man-sect-RAM-disk-img">
    <title>RAM-disk OS images</title>
    <indexterm><primary>Boot Process</primary>
    <secondary>RAM-disk image</secondary></indexterm>
    <para>
      The squashfs-based RAM-disk image is the file-system holding the node OS that is mounted
      as the root filesystem of the compute-nodes. It is assembled on the head-node(s) from the
      image modules, you are able to select in QluMan. Every RAM-disk image contains at least
      the core module. See the corresponding section of the <link
      xlink:href="../QluMan_Guide/index.html#sec-Qlustar-OS-Images___blank___">QluMan
      Guide</link> for more details. All available image modules are displayed and selectable
      in QluMan and the configuration and assembly of images is done automatically from within
      QluMan.
    </para>
    <note>
      <para>
	By default, the root password of a Qlustar OS image and hence the node booting it, is
	taken from the head-node(s) <filename>/etc/shadow</filename> file and is therefore the
	same as on the head-node(s). If you want to change this, you can call
	<command>qlustar-image-reconfigure &lt;image-name&gt;</command>. (Replacing
	&lt;image-name&gt; with the actual name of the image). You can then specify a different
	root password for the node OS image.
      </para>
    </note>
    <variablelist>
      <varlistentry>
	<term>
	  Changelogs
	</term>
	<listitem>
	  <para>
	    Any Qlustar node OS image contains changelogs of the various image modules it is
	    composed of. They are located in the directory
	    <filename>/usr/share/doc/qlustar-image</filename>. The main changelog file is
	    <filename>core.changelog.gz</filename>. The other files are automatically
	    generated. The files <filename>*.packages.version.gz</filename> lists the packages
	    each module is made of. The files <filename>*.contents.changelog*.gz</filename>
	    lists the files that were changed between each version, and
	    <filename>*.packages.changelog*.gz</filename> list differences in the package list
	    and versions. Hence, you always have detailed information about what has been
	    changed in new images as well as the package sources of their content.
	  </para>
	</listitem>
      </varlistentry>
    </variablelist>
    <section xml:id="admin-man-sect-RAM-disk-img-custom">
      <title>Static node OS image customization/modification</title>
      <indexterm><primary>Boot Process</primary>
      <secondary>RAM-disk image</secondary></indexterm>
      <para>
	Node OS images are regenerated automatically, when the image module packages they are
	based on are updated. That means, that files can't be simply modified or added to a
	generated image as the changes would be lost on the next update.
      </para>
      <para>
	<productname>Qlustar</productname> therefore provides a mechanism to add extra files to
	images every time they are rebuild and hence make changes permanent. Files can be added
	to all images or only to one specific image using the
	<application>qlustar-image-edit</application> tool. All the commands in this section
	must be executed as root on the head-node.
      </para>
      <para>
	To modify or add the file <filename>/some/path/filename</filename> to all images
	execute:
      </para>
      <screen>
	<prompt>0 root@cl-head ~ #</prompt><command>
	qlustar-image-edit -e /some/path/filename</command>
      </screen>
      <para>
	To modify/add the file to a specific image <replaceable>img</replaceable>:
      </para>
      <screen>
	<prompt>0 root@cl-head ~ #</prompt><command>
	qlustar-image-edit -e <replaceable>img</replaceable> /some/path/filename</command>
      </screen>
      <para>
	To edit the file again later, simply run the same command again.
      </para>
      <para>
	Files created this way will be located underneath the path
	<filename>/etc/qlustar/images</filename> on the head-node, either in the subdirectory
	<filename>common</filename> (for files entering all images) or in the subdirectory
	<filename><replaceable>img</replaceable></filename> (for files entering just the
	image <replaceable>img</replaceable>).
      </para>
      <para>
	The <emphasis>whole</emphasis> directory structure of a file is created there so the
	full path of the above examples would be
	<filename>/etc/qlustar/images/common/copy/some/path/filename</filename> or
	<filename>/etc/qlustar/images/<replaceable>img</replaceable>/copy/some/path/filename</filename>
	respectively. To undo adding such files to the images, simply remove these files.
      </para>
      <para>
	A second mode of <application>qlustar-image-edit</application> is to directly edit the
	generated images. Such changes are always temporary meaning they will be overwritten by
	image module updates. This method is suitable to apply a quick fix for a problem that
	is known to be solved in subsequent image module versions or for testing.
      </para>
      <para>
	To edit the initial RAMdisk of the image <replaceable>img</replaceable> execute:
	<screen>
	  <prompt>0 root@cl-head ~ #</prompt><command>
	  qlustar-image-edit -i <replaceable>img</replaceable></command>
	</screen>
	To edit the squashfs OS image do:
	<screen>
	  <prompt>0 root@cl-head ~ #</prompt><command>
	  qlustar-image-edit -s <replaceable>img</replaceable></command>
	</screen>
	In both cases, you will be placed into the root directory of the corresponding
	initrd/image. You can then manipulate any file in the initrd/image or add new ones to
	it. When done, enter <code>exit</code> and the initrd/image will be regenerated.
      </para>
      <warning>
	<para>
	  By manipulating the image in this way, you can easily break things and in the worst
	  case make the OS unbootable. Please be aware that you're on your own, if you choose
	  to experiment with the above methods. In other words: The Qlustar team won't be able
	  to give support for problems arising from a modified OS initrd/image.
	</para>
      </warning>
    </section>
  </section>
  <section xml:id="admin-man-sect-qluman-execd">
    <title>QluMan Remote Execution Server</title>
    <indexterm><primary>QluMan</primary>
    <secondary>Remote Execution Server</secondary></indexterm>
    <para>
      The QluMan execution server (<firstterm>qluman-execd</firstterm>) runs on any head- and
      compute-node of a Qlustar cluster. It is one of Qlustar's main components, responsible
      for executing remote commands as well as writing configurations to disk.
    </para>
    <section xml:id="admin-man-sect-execd-dynamic-boot-scripts">
      <title>Dynamic Node Customization/Configuration</title>
      <indexterm><primary>Boot Process</primary>
      <secondary>Dynamic Node Customization</secondary></indexterm>
      <para>
	When a compute-node boots, qluman-execd initially starts in a one-shot fashion (starts
	and exits when done with its configuration tasks) during the pre-systemd boot phase
	(see <xref linkend="admin-man-sect-comp-node-boot"/> for details). At this stage, it
	downloads the squashfs-based RAM-disk image via multicast from the head-node's qlumand
	service and performs a number of initialization/configuration tasks depending on the
	node's QluMan configuration options. Generated option files are written under
	<filename>/etc/qlustar/options.d</filename>. The following is a list of these tasks:
      </para>
      <variablelist>
	<varlistentry>
	  <term>
	    Network configuration
	  </term>
	  <listitem>
	    <para>
	      Configuration of all network parameters in the corresponding configuration files,
	      so that they can be activated later on by systemd. If the node boots Ubuntu or
	      Debian, the information is written to
	      <filename>/etc/network/interfaces.d/qluman</filename>, for CentOS in adapter
	      specific files under <filename>/etc/sysconfig/network-scripts</filename>.
	    </para>
	  </listitem>
	</varlistentry>
	<varlistentry>
	  <term>
	    Disk configuration
	  </term>
	  <listitem>
	    <para>
	      Writing of the host's QluMan defined disk configuration into the file
	      <filename>/etc/qlustar/options.d/disk-config</filename> for later use by the disk
	      initialization script.
	    </para>
	  </listitem>
	</varlistentry>
	<varlistentry>
	  <term>
	    Infiniband OpenSM activation
	  </term>
	  <listitem>
	    <para>
	      Activation of OpenSM in case the node is configured to run it.
	    </para>
	  </listitem>
	</varlistentry>
	<varlistentry>
	  <term>
	    IPMI IP configuration
	  </term>
	  <listitem>
	    <para>
	      Reconfiguration of the node's IPMI address, if a node is configured
	      correspondingly within QluMan.
	    </para>
	  </listitem>
	</varlistentry>
	<varlistentry>
	  <term>
	    UnionFS chroot
	  </term>
	  <listitem>
	    <para>
	      If configured in QluMan, a custom unionfs chroot will be setup rather than the
	      one that is defined in the Qlustar image.
	    </para>
	  </listitem>
	</varlistentry>
	<varlistentry>
	  <term>
	    SSH authorized_keys
	  </term>
	  <listitem>
	    <para>
	      The ssh keys that are configured in QluMan to allow password-less login to the
	      node as root, are copied into <filename>/root/.ssh/authorized_keys</filename>.
	    </para>
	  </listitem>
	</varlistentry>
	<varlistentry>
	  <term>
	    Miscellaneous
	  </term>
	  <listitem>
	    <para>
	      If configured in QluMan, mail transport will be activated on the node and ssh
	      access for normal users will be limited to those users having a running slurm or
	      torque job on the node by making changes to the pam config.
	    </para>
	  </listitem>
	</varlistentry>
      </variablelist>
      <para>
	For details about the configuration of the above components, see the corresponding
	section of the <link
      xlink:href="../QluMan_Guide/index.html#chap-RX-Engine___blank___">QluMan Guide</link>.
      </para>
    </section>
  </section>
</section>
